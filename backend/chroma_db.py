"""
ChromaDBå‘é‡æ•°æ®åº“é›†æˆæ¨¡å—
ç”¨äºå­˜å‚¨å’Œæ£€ç´¢æ–‡æ¡£å‘é‡
"""

import os
import chromadb
from chromadb.config import Settings
from typing import List, Dict, Any, Optional
import uuid
import json
from datetime import datetime


class ChromaVectorDB:
    """ChromaDBå‘é‡æ•°æ®åº“ç®¡ç†å™¨"""
    
    def __init__(self, persist_directory: str = "./chroma_db"):
        """
        åˆå§‹åŒ–ChromaDB
        
        Args:
            persist_directory: æ•°æ®åº“æŒä¹…åŒ–ç›®å½•
        """
        self.persist_directory = persist_directory
        os.makedirs(persist_directory, exist_ok=True)
        
        try:
            # åˆ›å»ºChromaDBå®¢æˆ·ç«¯
            self.client = chromadb.PersistentClient(path=persist_directory)
            
            # è·å–æˆ–åˆ›å»ºé›†åˆ
            self.collection = self.client.get_or_create_collection(
                name="documents",
                metadata={"description": "æ–‡æ¡£å‘é‡å­˜å‚¨é›†åˆ"}
            )
            
            print(f"âœ… ChromaDBåˆå§‹åŒ–æˆåŠŸï¼Œå­˜å‚¨è·¯å¾„: {persist_directory}")
            
        except Exception as e:
            print(f"âŒ ChromaDBåˆå§‹åŒ–å¤±è´¥: {str(e)}")
            raise
    
    def store_document_chunks(self, file_id: str, filename: str, chunks: List[Dict[str, Any]], embeddings: List[List[float]]) -> bool:
        """
        å­˜å‚¨æ–‡æ¡£å—åˆ°å‘é‡æ•°æ®åº“
        
        Args:
            file_id: æ–‡ä»¶ID
            filename: æ–‡ä»¶å
            chunks: æ–‡æ¡£å—åˆ—è¡¨
            embeddings: å¯¹åº”çš„å‘é‡åµŒå…¥åˆ—è¡¨
            
        Returns:
            å­˜å‚¨æ˜¯å¦æˆåŠŸ
        """
        try:
            if len(chunks) != len(embeddings):
                raise ValueError(f"å—æ•°é‡({len(chunks)})ä¸å‘é‡æ•°é‡({len(embeddings)})ä¸åŒ¹é…")
            
            # å‡†å¤‡æ•°æ®
            ids = []
            documents = []
            metadatas = []
            
            for i, (chunk, embedding) in enumerate(zip(chunks, embeddings)):
                chunk_id = f"{file_id}_chunk_{i}"
                ids.append(chunk_id)
                
                # æ–‡æ¡£å†…å®¹
                documents.append(chunk.get('content', ''))
                
                # å…ƒæ•°æ®
                metadata = {
                    "file_id": file_id,
                    "filename": filename,
                    "chunk_index": i,
                    "chunk_title": chunk.get('title', ''),
                    "chunk_summary": chunk.get('summary', ''),
                    "chunk_type": chunk.get('type', 'unknown'),
                    "created_at": datetime.now().isoformat(),
                    "content_length": len(chunk.get('content', ''))
                }
                metadatas.append(metadata)
            
            # æ·»åŠ åˆ°é›†åˆ
            self.collection.add(
                ids=ids,
                documents=documents,
                embeddings=embeddings,
                metadatas=metadatas
            )
            
            print(f"âœ… æ–‡æ¡£å—å­˜å‚¨æˆåŠŸ: {filename} ({len(chunks)} å—)")
            return True
            
        except Exception as e:
            print(f"âŒ å­˜å‚¨æ–‡æ¡£å—å¤±è´¥: {str(e)}")
            return False
    
    def search_similar_documents(self, query_text: str, n_results: int = 5, file_id: Optional[str] = None) -> List[Dict[str, Any]]:
        """
        æœç´¢ç›¸ä¼¼æ–‡æ¡£
        
        Args:
            query_text: æŸ¥è¯¢æ–‡æœ¬
            n_results: è¿”å›ç»“æœæ•°é‡
            file_id: å¯é€‰ï¼Œé™åˆ¶æœç´¢ç‰¹å®šæ–‡ä»¶
            
        Returns:
            ç›¸ä¼¼æ–‡æ¡£åˆ—è¡¨
        """
        try:
            # æ„å»ºæŸ¥è¯¢æ¡ä»¶
            where_clause = {}
            if file_id:
                where_clause["file_id"] = file_id
            
            # æ‰§è¡Œæœç´¢
            results = self.collection.query(
                query_texts=[query_text],
                n_results=n_results,
                where=where_clause if where_clause else None
            )
            
            # æ ¼å¼åŒ–ç»“æœ
            formatted_results = []
            if results['documents'] and len(results['documents']) > 0:
                for i in range(len(results['documents'][0])):
                    result = {
                        "id": results['ids'][0][i],
                        "content": results['documents'][0][i],
                        "distance": results['distances'][0][i],
                        "metadata": results['metadatas'][0][i]
                    }
                    formatted_results.append(result)
            
            return formatted_results
            
        except Exception as e:
            print(f"âŒ æœç´¢å¤±è´¥: {str(e)}")
            return []
    
    def get_file_chunks(self, file_id: str) -> List[Dict[str, Any]]:
        """
        è·å–ç‰¹å®šæ–‡ä»¶çš„æ‰€æœ‰å—
        
        Args:
            file_id: æ–‡ä»¶ID
            
        Returns:
            æ–‡ä»¶å—åˆ—è¡¨
        """
        try:
            results = self.collection.get(
                where={"file_id": file_id}
            )
            
            chunks = []
            if results['documents']:
                for i in range(len(results['documents'])):
                    chunk = {
                        "id": results['ids'][i],
                        "content": results['documents'][i],
                        "metadata": results['metadatas'][i]
                    }
                    chunks.append(chunk)
            
            # æŒ‰chunk_indexæ’åº
            chunks.sort(key=lambda x: x['metadata'].get('chunk_index', 0))
            return chunks
            
        except Exception as e:
            print(f"âŒ è·å–æ–‡ä»¶å—å¤±è´¥: {str(e)}")
            return []
    
    def delete_file_chunks(self, file_id: str) -> bool:
        """
        åˆ é™¤ç‰¹å®šæ–‡ä»¶çš„æ‰€æœ‰å—
        
        Args:
            file_id: æ–‡ä»¶ID
            
        Returns:
            åˆ é™¤æ˜¯å¦æˆåŠŸ
        """
        try:
            # è·å–è¦åˆ é™¤çš„å—ID
            results = self.collection.get(
                where={"file_id": file_id}
            )
            
            if results['ids']:
                self.collection.delete(ids=results['ids'])
                print(f"âœ… å·²åˆ é™¤æ–‡ä»¶å—: {file_id} ({len(results['ids'])} å—)")
                return True
            else:
                print(f"âš ï¸  æ–‡ä»¶å—ä¸å­˜åœ¨: {file_id}")
                return True
                
        except Exception as e:
            print(f"âŒ åˆ é™¤æ–‡ä»¶å—å¤±è´¥: {str(e)}")
            return False
    
    def get_collection_stats(self) -> Dict[str, Any]:
        """
        è·å–é›†åˆç»Ÿè®¡ä¿¡æ¯
        
        Returns:
            ç»Ÿè®¡ä¿¡æ¯å­—å…¸
        """
        try:
            # è·å–æ‰€æœ‰æ•°æ®
            all_data = self.collection.get()
            
            total_chunks = len(all_data['ids']) if all_data['ids'] else 0
            
            # ç»Ÿè®¡æ–‡ä»¶æ•°é‡
            file_ids = set()
            if all_data['metadatas']:
                for metadata in all_data['metadatas']:
                    file_ids.add(metadata.get('file_id', ''))
            
            stats = {
                "total_files": len(file_ids),
                "total_chunks": total_chunks,
                "collection_name": self.collection.name,
                "persist_directory": self.persist_directory
            }
            
            return stats
            
        except Exception as e:
            print(f"âŒ è·å–ç»Ÿè®¡ä¿¡æ¯å¤±è´¥: {str(e)}")
            return {"error": str(e)}
    
    def backup_collection(self, backup_path: str) -> bool:
        """
        å¤‡ä»½é›†åˆæ•°æ®
        
        Args:
            backup_path: å¤‡ä»½æ–‡ä»¶è·¯å¾„
            
        Returns:
            å¤‡ä»½æ˜¯å¦æˆåŠŸ
        """
        try:
            all_data = self.collection.get()
            
            backup_data = {
                "collection_name": self.collection.name,
                "backup_time": datetime.now().isoformat(),
                "data": all_data
            }
            
            with open(backup_path, 'w', encoding='utf-8') as f:
                json.dump(backup_data, f, ensure_ascii=False, indent=2)
            
            print(f"âœ… æ•°æ®å¤‡ä»½æˆåŠŸ: {backup_path}")
            return True
            
        except Exception as e:
            print(f"âŒ æ•°æ®å¤‡ä»½å¤±è´¥: {str(e)}")
            return False


def test_chroma_db():
    """æµ‹è¯•ChromaDBåŠŸèƒ½"""
    try:
        # åˆ›å»ºæµ‹è¯•å®ä¾‹
        db = ChromaVectorDB("./test_chroma_db")
        
        # æµ‹è¯•æ•°æ®
        test_chunks = [
            {
                "title": "æµ‹è¯•æ ‡é¢˜1",
                "content": "è¿™æ˜¯ç¬¬ä¸€ä¸ªæµ‹è¯•æ–‡æ¡£å—çš„å†…å®¹",
                "summary": "ç¬¬ä¸€ä¸ªå—çš„æ‘˜è¦",
                "type": "test"
            },
            {
                "title": "æµ‹è¯•æ ‡é¢˜2", 
                "content": "è¿™æ˜¯ç¬¬äºŒä¸ªæµ‹è¯•æ–‡æ¡£å—çš„å†…å®¹",
                "summary": "ç¬¬äºŒä¸ªå—çš„æ‘˜è¦",
                "type": "test"
            }
        ]
        
        # æµ‹è¯•å‘é‡ï¼ˆéšæœºï¼‰
        import random
        test_embeddings = [[random.random() for _ in range(1536)] for _ in range(2)]
        
        # æµ‹è¯•å­˜å‚¨
        success = db.store_document_chunks(
            file_id="test_file_1",
            filename="test_document.pdf",
            chunks=test_chunks,
            embeddings=test_embeddings
        )
        
        if success:
            print("âœ… ChromaDBæµ‹è¯•æˆåŠŸ")
            
            # æµ‹è¯•ç»Ÿè®¡
            stats = db.get_collection_stats()
            print(f"ğŸ“Š æ•°æ®åº“ç»Ÿè®¡: {stats}")
            
        else:
            print("âŒ ChromaDBæµ‹è¯•å¤±è´¥")
            
    except Exception as e:
        print(f"âŒ ChromaDBæµ‹è¯•å‡ºé”™: {str(e)}")


if __name__ == "__main__":
    test_chroma_db()