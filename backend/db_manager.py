#!/usr/bin/env python3
"""
æ•°æ®åº“ç»´æŠ¤å’Œç®¡ç†è„šæœ¬
ç”¨äºæ•°æ®åº“è¿ç§»ã€æ¸…ç†å’Œç»Ÿè®¡
"""

import os
import sys
import argparse
from datetime import datetime, timedelta

# æ·»åŠ å½“å‰ç›®å½•åˆ°Pythonè·¯å¾„
sys.path.insert(0, os.path.dirname(os.path.abspath(__file__)))

from database import get_database_manager, DatabaseManager

def init_database():
    """åˆå§‹åŒ–æ•°æ®åº“"""
    try:
        db_manager = DatabaseManager()
        print("âœ… æ•°æ®åº“åˆå§‹åŒ–æˆåŠŸ")
        return True
    except Exception as e:
        print(f"âŒ æ•°æ®åº“åˆå§‹åŒ–å¤±è´¥: {str(e)}")
        return False

def show_statistics():
    """æ˜¾ç¤ºæ•°æ®åº“ç»Ÿè®¡ä¿¡æ¯"""
    try:
        db_manager = get_database_manager()
        stats = db_manager.get_processing_statistics()
        
        print("\nğŸ“Š æ•°æ®åº“ç»Ÿè®¡ä¿¡æ¯:")
        print(f"æ€»æ–‡ä»¶æ•°: {stats['total_files']}")
        print(f"å·²å®Œæˆ: {stats['completed_files']}")
        print(f"å¤„ç†ä¸­: {stats['processing_files']}")
        print(f"ç­‰å¾…å¤„ç†: {stats['pending_files']}")
        print(f"å¤±è´¥: {stats['error_files']}")
        print(f"æ€»æ–‡æ¡£å—: {stats['total_chunks']}")
        print(f"æˆåŠŸç‡: {stats['success_rate']}%")
        
        # æ˜¾ç¤ºé”™è¯¯æ–‡ä»¶
        error_files = db_manager.get_error_files()
        if error_files:
            print(f"\nâŒ é”™è¯¯æ–‡ä»¶ ({len(error_files)} ä¸ª):")
            for file_record in error_files[:5]:  # åªæ˜¾ç¤ºå‰5ä¸ª
                print(f"  - {file_record.filename}: {file_record.last_error}")
            if len(error_files) > 5:
                print(f"  ... è¿˜æœ‰ {len(error_files) - 5} ä¸ªé”™è¯¯æ–‡ä»¶")
        
        return True
    except Exception as e:
        print(f"âŒ è·å–ç»Ÿè®¡ä¿¡æ¯å¤±è´¥: {str(e)}")
        return False

def cleanup_old_data(days=7):
    """æ¸…ç†æ—§æ•°æ®"""
    try:
        db_manager = get_database_manager()
        result = db_manager.cleanup_old_records(days=days)
        
        print(f"ğŸ§¹ æ¸…ç†å®Œæˆ:")
        print(f"åˆ é™¤æ–‡ä»¶è®°å½•: {result['deleted_files']} ä¸ª")
        print(f"åˆ é™¤å¤„ç†æ—¥å¿—: {result['deleted_logs']} ä¸ª")
        return True
    except Exception as e:
        print(f"âŒ æ¸…ç†å¤±è´¥: {str(e)}")
        return False

def export_data(output_file):
    """å¯¼å‡ºæ•°æ®"""
    try:
        import json
        db_manager = get_database_manager()
        
        # è·å–æ‰€æœ‰æ–‡ä»¶è®°å½•
        all_files = db_manager.get_all_file_records()
        
        export_data = {
            "export_time": datetime.now().isoformat(),
            "total_files": len(all_files),
            "files": []
        }
        
        for file_record in all_files:
            file_data = {
                "id": file_record.id,
                "filename": file_record.filename,
                "status": file_record.status,
                "progress": file_record.progress,
                "total_pages": file_record.total_pages,
                "chunks_count": file_record.chunks_count,
                "error_count": file_record.error_count,
                "created_at": file_record.created_at.isoformat(),
                "updated_at": file_record.updated_at.isoformat()
            }
            
            # è·å–å¤„ç†æ—¥å¿—
            logs = db_manager.get_processing_logs(file_record.id)
            file_data["logs"] = [
                {
                    "stage": log.stage,
                    "status": log.status,
                    "message": log.message,
                    "duration": log.duration,
                    "created_at": log.created_at.isoformat()
                }
                for log in logs
            ]
            
            export_data["files"].append(file_data)
        
        with open(output_file, 'w', encoding='utf-8') as f:
            json.dump(export_data, f, ensure_ascii=False, indent=2)
        
        print(f"âœ… æ•°æ®å¯¼å‡ºæˆåŠŸ: {output_file}")
        print(f"å¯¼å‡ºæ–‡ä»¶æ•°: {len(all_files)}")
        return True
    except Exception as e:
        print(f"âŒ æ•°æ®å¯¼å‡ºå¤±è´¥: {str(e)}")
        return False

def reset_database():
    """é‡ç½®æ•°æ®åº“ï¼ˆå±é™©æ“ä½œï¼‰"""
    try:
        confirm = input("âš ï¸  è¿™å°†åˆ é™¤æ‰€æœ‰æ•°æ®ï¼Œç¡®è®¤ç»§ç»­ï¼Ÿ(è¾“å…¥ 'YES' ç¡®è®¤): ")
        if confirm != "YES":
            print("æ“ä½œå·²å–æ¶ˆ")
            return False
        
        # åˆ é™¤æ•°æ®åº“æ–‡ä»¶
        db_file = "doc_vector.db"
        if os.path.exists(db_file):
            os.remove(db_file)
            print(f"ğŸ—‘ï¸  åˆ é™¤æ•°æ®åº“æ–‡ä»¶: {db_file}")
        
        # é‡æ–°åˆå§‹åŒ–
        init_database()
        print("âœ… æ•°æ®åº“é‡ç½®å®Œæˆ")
        return True
    except Exception as e:
        print(f"âŒ æ•°æ®åº“é‡ç½®å¤±è´¥: {str(e)}")
        return False

def main():
    parser = argparse.ArgumentParser(description="æ•°æ®åº“ç»´æŠ¤å’Œç®¡ç†å·¥å…·")
    parser.add_argument("command", choices=[
        "init", "stats", "cleanup", "export", "reset"
    ], help="è¦æ‰§è¡Œçš„å‘½ä»¤")
    
    parser.add_argument("--days", type=int, default=7, 
                       help="æ¸…ç†å¤šå°‘å¤©å‰çš„æ•°æ® (é»˜è®¤: 7)")
    parser.add_argument("--output", type=str, default="export.json",
                       help="å¯¼å‡ºæ–‡ä»¶å (é»˜è®¤: export.json)")
    
    args = parser.parse_args()
    
    print(f"ğŸš€ æ‰§è¡Œå‘½ä»¤: {args.command}")
    
    if args.command == "init":
        success = init_database()
    elif args.command == "stats":
        success = show_statistics()
    elif args.command == "cleanup":
        success = cleanup_old_data(args.days)
    elif args.command == "export":
        success = export_data(args.output)
    elif args.command == "reset":
        success = reset_database()
    else:
        print(f"æœªçŸ¥å‘½ä»¤: {args.command}")
        success = False
    
    if success:
        print("âœ… æ“ä½œå®Œæˆ")
        sys.exit(0)
    else:
        print("âŒ æ“ä½œå¤±è´¥")
        sys.exit(1)

if __name__ == "__main__":
    main()